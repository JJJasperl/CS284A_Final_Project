<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS284A Final Project</title>
    <!-- Include MathJax for equation rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f9f9f9;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #3498db;
        }
        h2 {
            margin-top: 30px;
            padding-bottom: 10px;
            border-bottom: 1px solid #e0e0e0;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .team-members {
            background-color: #eaf2f8;
            padding: 15px;
            border-radius: 5px;
            text-align: center;
            margin: 20px 0;
        }
        .equation {
            text-align: center;
            margin: 20px 0;
        }
        .image-caption {
            text-align: center;
            font-style: italic;
            margin-top: 10px;
            color: #666;
        }
        .week {
            margin-left: 20px;
        }
        .reference {
            margin-left: 20px;
            margin-bottom: 10px;
        }
        .content {
            text-align: center;
            margin: 30px 0;
        }
        .link {
            display: block;
            margin: 15px 0;
            padding: 10px 15px;
            background-color: #3498db;
            color: #fff;
            text-decoration: none;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            transition: background-color 0.3s ease;
        }
        .link:hover {
            background-color: #2c3e50;
        }
        .icon-row {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        .icon {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-decoration: none;
            color: #333;
            transition: transform 0.3s ease;
        }
        .icon img {
            width: 80px;
            height: 80px;
            margin-bottom: 10px;
        }
        .icon:hover {
            transform: scale(1.1);
        }
        .button-row {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        .button {
            padding: 10px 20px;
            background-color: #3498db;
            color: #fff;
            text-decoration: none;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            transition: background-color 0.3s ease;
            font-size: 1em;
            font-weight: bold;
        }
        .button:hover {
            background-color: #2c3e50;
        }
    </style>
</head>
<body>
    <h1>Lumen: Global Illumination in Unreal Engine</h1>
    <div class="content">
        <p style="font-size: 1.5em; font-weight: bold;">Milestone</p>
        <div class="button-row">
            <a href="https://drive.google.com/file/d/14OhQT9DK0IawaSjFrociqO-FydxXB3uk/view?usp=sharing" target="_blank" class="button">Video</a>
            <a href="https://docs.google.com/presentation/d/1ufrtLGJfFDINMAVb6WRvFgbwY6hgtv2Lsr-7qAYlbkc/edit?usp=drive_link" target="_blank" class="button">PPT</a>
        </div>
    </div>
    
    <div class="team-members">
        <p>Jasper Liu, Zihan Liao, Junming Chen, Jinglun Zhang</p>
        <h3>UC Berkeley</h3>
    </div>
    
    
    <blockquote><strong><em>"Real-time global illumination has always been a holy grail of computer graphics."</em></strong></blockquote>
    <p>Lumen is a dynamic global illumination and reflections system implemented in Unreal Engine (UE) 5. Lumen Global Illumination solves diffuse indirect lighting. For example, light bouncing diffusely off a surface picks up the color of that surface and reflects the colored light onto other nearby surfaces, creating an effect called color bleed. Meshes in scenes also block indirect lighting, which also produces indirect shadowing. The magic of Lumen is its ability to simulate infinite diffuse bounces in real time. In this project, we aim to explore how Lumen realizes real-time global illumination and improve the rendering efficiency without compromising too many visual effects.</p>
    
    <!-- image -->
    <img src="fig1.png" alt="Lumen Global Illumination" />
    <div class="image-caption">Figure 1: Example scene from Unreal official sites that demonstrates the rendering effect of Lumen</div>

    <h2>Introduction and Problem Description</h2>

    <p>
    Lumen is a dynamic global illumination and reflections system implemented in Unreal Engine (UE) 5. Lumen Global Illumination solves diffuse indirect lighting.
    In this final project, we aim to explore and implement the core and essential idea behind Lumen. Ignoring the complex engineering and framework limitations, we want to build a global illumination renderer that traces the ray to collect direct light, but uses a Radiosity-based method for accumulating indirect light as Lumen does. Our goal is to achieve an amazing global illumination quality faster in a real-time rendering fashion.
    </p>

    <h3>Solving the Discretized Rendering Equation</h3>

    <p>
    In general, the difficulty of real-time global illumination lies in solving the rendering equation:
    </p>

    <div class="equation">
        \[
        B(x) = B_e(x) + \rho(x) \cdot \int_M B(y) \cdot \frac{G(x \leftrightarrow y) \cdot V(x \leftrightarrow y)}{\pi} \, dA_y
        \]
    </div>

    <p>
    By discretizing the equation and breaking the continuous surface into surface elements, we are able to reach the following linear equations:
    </p>

    <div class="equation">
        \[
        B_i(u) = B_{e,i}(u) + \rho_i \sum_{j=1}^n \sum_v F_{ij}(u,v) B_j(v)
        \]
    </div>

    <p>
    where \( B_i(u) \) represents the radiance of the \( i \)-th surface element at direction \( v \), \( B_{e,i} \) is the emission from the \( i \)-th surface element.
    </p>

    <p>
    Now the question is how to efficiently solve this linear equation. One way is to use Gaussian elimination, but the time complexity goes up in cubic order with respect to the number of surface elements.
    </p>

    <h3>Lumen's Approach: Reuse</h3>

    <p>
    Lumen incorporates two new ideas: surface and radiance cache. They sample and store some radiance \( B_i(v) \) of the \( i \)-th surface element and the corresponding material information at the \( t \)-th time step, and use them to update the \( B \)s at the \( t+1 \)-th time step.
    </p>

    <div class="equation">
        \[
        B_i^{t+1}(u) = B_{e,i}(u) + \rho_i \sum_{j=1}^{N} \sum_v F_{ij}(u,v) \cdot B_j^t(v)
        \]
    </div>

    <p>
    This method relies on one condition to converge quickly and accurately to the true global illumination solution: the radiance of the \( i+1 \)-th surface element at the \( t \)-th time step does not differ significantly from itself at the \( t+1 \)-th time step. And this condition is generally true in scenarios where real-time rendering is needed.
    </p>

    <h2>Overview of the Methods and Progress</h2>

    <h3>Ray Marching and Mesh Distance Fields</h3>

    <p>
    While the previously introduced equation provides the theoretical foundation for real-time global illumination, our implementation experience reveals that the core strength of Unreal Engine 5's Lumen system lies primarily in its engineering design. Several key challenges must be addressed to enable practical performance, among which the first is:
    </p>

    <ul>
        <li>
            Assuming unlimited parallelism, Equation&nbsp;\( B_i^{t+1}(u) = B_{e,i}(u) + \rho_i \sum_{j=1}^{N} \sum_v F_{ij}(u,v) \cdot B_j^t(v) \) reduces the computational complexity of solving the discretized rendering equation \( B_i(u) = B_{e,i}(u) + \rho_i \sum_{j=1}^n \sum_v F_{ij}(u,v) B_j(v) \) to \( O(N) \), where each thread independently updates a single \( B_i^{t+1} \). However, for scenes containing a large number of triangles, this complexity remains insufficient for real-time performance.
        </li>
    </ul>

    <p>
    Lumen addresses this challenge by casting a set of rays from each surface element. For the \( i \)-th surface element, rays are cast to identify contributing \( B_j^t \) values, compute the associated form factors \( F_{ij} \), and update \( B_i^{t+1} \). This strategy effectively approximates the full summation by randomly sampling a subset of contributing elements rather than exhaustively iterating over all possible surface pairs. Given infinite parallelism, this approach reduces the complexity to \( O(\text{rays} \times O(\text{ray-surface intersection})) \).
    </p>

    <p>
    The second engineering challenge is as follows:
    </p>

    <ul>
        <li>
            Conventional ray-triangle intersection acceleration structures, such as bounding volume hierarchies (BVHs), are computationally expensive. According to Wright et al., real-time performance using such structures is limited to approximately half a ray per pixel. Additionally, tree-based data structures like BVHs exhibit poor performance on GPUs due to their branch-heavy execution patterns.
        </li>
    </ul>

    <p>
    To overcome this, Lumen avoids direct ray-triangle intersection and instead employs ray marching accelerated by signed distance fields (SDFs), which are significantly more GPU-friendly.
    </p>

    <h3>Implementation Progress 1: World-Space SDF</h3>

    <p>
    We began by implementing a world-space SDF using a 3D texture that encapsulates the entire scene’s bounding box, with a resolution of \( 256 \times 256 \times 256 \). The SDF is computed and updated in real time using the Jump Flooding Algorithm (JFA). The result of this initial implementation is illustrated in Figure 1.
    </p>
    
    <p>
    However, this implementation exhibits several limitations. Achieving adequate geometric detail necessitates high-resolution SDFs, yet JFA only provides an approximation, which introduces imprecision at finer resolutions. As shown in Figure 1, some voxels remain incorrectly updated, resulting in noticeable artifacts (e.g., white pixels indicating rays that fail to intersect geometry). Furthermore, the performance is suboptimal; rendering the hit point lengths at this resolution yields only ~25 FPS.
    </p>
    
    <div style="display: flex; justify-content: space-around; flex-wrap: wrap;">
        <div style="flex: 0 0 45%; text-align: center;">
            <img src="fig/stupid_sdf.png" alt="Our world-space SDF" style="max-width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
            <div class="image-caption">Figure 1a: Our world-space SDF at resolution \(256 \times 256 \times 256\).</div>
        </div>
        <div style="flex: 0 0 45%; text-align: center;">
            <img src="fig/ue_sdf.png" alt="UE5 Mesh SDF" style="max-width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
            <div class="image-caption">Figure 1b: UE5 Mesh SDF with resolution \(56 \times 49 \times 56\).</div>
        </div>
    </div>
    
    <p>
    Upon reviewing documentation and visuals from Unreal Engine 5, we identified Figure 1b, which shows a mesh SDF implementation with a much lower resolution of \(56 \times 49 \times 56\). This observation led us to hypothesize that Lumen maintains a separate SDF for each mesh, computed in the object space and covering only the mesh’s bounding volume. During ray marching, the bounding box of the mesh is first intersected, and marching proceeds in object space to find the hit point on the mesh surface. This insight is consistent with Lumen’s use of the term <em>Mesh Distance Field</em>.
    </p>
    
    <h3>Implementation Progress 2: Mesh-Space SDF</h3>

    <p>
    Based on this understanding, we implemented mesh-space SDFs. Each mesh maintains its own distance field within object space. This revision significantly improved both accuracy and performance, achieving approximately 160 FPS. The result is shown in Figure 2. Minor visual artifacts, such as aliasing, are attributable to the lack of trilinear filtering in our SDF sampling.
    </p>

    <div style="text-align: center;">
        <img src="fig/revised_sdf.png" alt="Mesh-space SDF result" style="max-width: 50%; border: 1px solid #ccc; border-radius: 5px;" />
        <div class="image-caption">Figure 2: Our mesh-space SDF implementation (without trilinear filtering).</div>
    </div>

    <h3>Surface and Radiance Caching Using Cards</h3>

    <p>
    Having established a method to compute surface-ray intersections via signed distance field (SDF) ray marching, we encounter the third key challenge:
    </p>

    <ul>
        <li>
            Ray marching using SDFs yields only the spatial coordinates of the surface intersection, but it does not provide information about the corresponding surface element or the material properties at the hit point. In other words, we cannot directly obtain \( F_{ij} \) and \( B_j^t \) in Equation \( B_i^{t+1}(u) = B_{e,i}(u) + \rho_i \sum_{j=1}^{N} \sum_v F_{ij}(u,v) \cdot B_j^t(v) \).
        </li>
    </ul>

    <p>
    An initial idea was to allocate a texture with the same resolution as the mesh’s SDF to store surface properties. However, this approach quickly proved impractical. The primary reason is that the discretized rendering equation assumes a purely diffuse scene, wherein only radiosity must be stored. For more complex materials—such as mirrors—radiance samples over the hemisphere must be retained. For instance, if each surface element casts 64 rays to sample hemispherical radiance, and each sample stores a direction (3 floats), probability (1 float), and value (3 floats), this results in 1792 bytes per surface element. Given Lumen's maximum supported SDF resolution of \(128 \times 128 \times 128\), the total memory requirement would exceed 3.5 GB per object, which is prohibitively large.
    </p>

    <div style="text-align: center;">
        <img src="fig/ue_cards.png" alt="UE5 Cards Structure" style="max-width: 50%; border: 1px solid #ccc; border-radius: 5px;" />
        <div class="image-caption">Figure 3: UE5 surface cache structure using "Cards".</div>
    </div>
    <p>
        Figure 3, sourced from the official Unreal Engine documentation, reveals Lumen’s approach to mitigating this storage overhead. The key observation is that the axis-aligned bounding box of a mesh typically contains substantial regions of empty space that do not correspond to the actual surface and thus need not be cached.
        </p>
        
        <p>
        To avoid caching this non-surface volume, Lumen introduces the concept of <strong>Cards</strong>. A card is a spatial cuboid that is discretized to store surface data. A given mesh is decomposed into multiple cards, each capturing a portion of its surface. This subdivision reduces the amount of unused space represented in the cache. However, it introduces an additional lookup cost—during ray intersection, one must identify the specific card containing the hit point to access the corresponding surface data. In the limiting case where a mesh uses a single card, the scheme degenerates into a full-object-space cache with resolution equal to that of the SDF. Thus, the number of cards offers a tunable tradeoff between memory efficiency and access performance.
        </p>
        
        <h3>Implementation Progress 3: Card Generation</h3>
        
        <p>
        To enable card-based caching, we implemented a mesh decomposition strategy using the K-Means clustering algorithm to partition the surface point cloud into a specified number of clusters (equal to the number of desired cards). For each cluster, we computed an oriented bounding box (OBB) using principal component analysis (PCA). The resulting card structure is visualized in Figure 4a. In parallel, we also implemented trilinear interpolation for SDF sampling to improve ray-marching precision.
        </p>
        
        <h3>Implementation Progress 4: Surface Normal Cache</h3>
        
        <p>
        Following card generation, we implemented a surface normal cache. This cache stores the normal vectors corresponding to the discretized surface points within each card. A visualization of the resulting normals is provided in Figure 4b. The visualization frame rate is now about 80 fps.
        </p>
        
        <div style="display: flex; justify-content: space-around; flex-wrap: wrap;">
            <div style="flex: 0 0 45%; text-align: center;">
                <img src="fig/bunny_cards.png" alt="Card generation for CBbunny" style="max-width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
                <div class="image-caption">Figure 4a: Card generation for the CBbunny scene with a maximum of 12 cards.</div>
            </div>
            <div style="flex: 0 0 45%; text-align: center;">
                <img src="fig/bunny_normal.png" alt="Surface normal visualization" style="max-width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
                <div class="image-caption">Figure 4b: Visualization of cached surface normals.</div>
            </div>
        </div>
        
        <h2>Future Work: Surface and Radiance Cache Implementation</h2>

        <p>
        Our subsequent development efforts will focus on the following objectives:
        </p>
        
        <ol>
            <li><strong>Integration of Surface Texture Data:</strong> We aim to incorporate material-specific surface information into the cache, with initial support for two fundamental material types: diffuse and specular (mirror-like) surfaces.</li>
        
            <li><strong>Radiance Cache Implementation and Update Strategy:</strong> We plan to design and implement a radiance cache system, incorporating Lumen's temporal reuse strategy to efficiently update cached radiance values across frames.</li>
        
            <li><strong>Importance-Based Radiance Sampling:</strong> We will implement importance sampling techniques for radiance acquisition, enabling more accurate and efficient integration by prioritizing samples that contribute significantly to the lighting solution.</li>
        </ol>
    
    <h2>Resources</h2>
    <div class="reference">[1] Jaroslav Křivánek. Computer graphics III – Rendering equation and its solution</div>
    <div class="reference">[2] UE5 Unreal Engine: <a href="https://github.com/EpicGames/UnrealEngine.git" target="_blank">https://github.com/EpicGames/UnrealEngine.git</a></div>
</body>
</html>
